{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Training Source Models\n",
    "\n",
    "This notebook trains two neural networks to solve 4-bit binary addition:\n",
    "1. **Monolithic MLP** - Single dense network\n",
    "2. **Compositional Modular Network** - Bit-wise processing modules\n",
    "\n",
    "Both achieve 100% accuracy but learn fundamentally different internal representations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths for Colab/cloud environments\n",
    "import os\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "print(\"\u2713 Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate 4-bit Addition Dataset\n",
    "\n",
    "All possible 4-bit + 4-bit additions (512 examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_4bit_addition_dataset():\n",
    "    \"\"\"Generate all 512 possible 4-bit + 4-bit additions.\"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    \n",
    "    for a in range(16):  # 4-bit: 0-15\n",
    "        for b in range(16):\n",
    "            # Convert to binary (4 bits each)\n",
    "            a_bits = [(a >> i) & 1 for i in range(4)]\n",
    "            b_bits = [(b >> i) & 1 for i in range(4)]\n",
    "            \n",
    "            # Concatenate: [a0, a1, a2, a3, b0, b1, b2, b3]\n",
    "            input_bits = a_bits + b_bits\n",
    "            \n",
    "            # Output: 5-bit sum (0-30)\n",
    "            sum_val = a + b\n",
    "            output_bits = [(sum_val >> i) & 1 for i in range(5)]\n",
    "            \n",
    "            inputs.append(input_bits)\n",
    "            outputs.append(output_bits)\n",
    "    \n",
    "    return np.array(inputs, dtype=np.float32), np.array(outputs, dtype=np.float32)\n",
    "\n",
    "# Generate dataset\n",
    "X, y = generate_4bit_addition_dataset()\n",
    "print(f\"Dataset shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"Example: {X[0]} + {X[1]} = {y[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create dataloader\n",
    "dataset = AdditionDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Monolithic MLP\n",
    "\n",
    "Simple feed-forward network: 8 \u2192 64 \u2192 64 \u2192 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonolithicMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        hidden = torch.relu(self.fc2(x))  # This is what we'll extract\n",
    "        x = torch.sigmoid(self.fc3(hidden))\n",
    "        return x, hidden\n",
    "\n",
    "mono_model = MonolithicMLP().to(device)\n",
    "print(f\"Monolithic parameters: {sum(p.numel() for p in mono_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, train_loader, epochs=100, lr=0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for epoch in tqdm(range(epochs), desc=\"Training\"):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Accuracy: all 5 bits must match\n",
    "            pred_bits = (outputs > 0.5).float()\n",
    "            correct += (pred_bits == targets).all(dim=1).sum().item()\n",
    "            total += inputs.size(0)\n",
    "        \n",
    "        losses.append(epoch_loss / len(train_loader))\n",
    "        accuracies.append(100 * correct / total)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss={losses[-1]:.4f}, Acc={accuracies[-1]:.2f}%\")\n",
    "    \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train monolithic model\n",
    "print(\"Training Monolithic MLP...\")\n",
    "mono_losses, mono_accs = train_model(mono_model, train_loader, epochs=100)\n",
    "\n",
    "# Save model\n",
    "torch.save(mono_model.state_dict(), '../models/monolithic_4bit.pth')\n",
    "print(f\"\\nFinal accuracy: {mono_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Compositional Modular Network\n",
    "\n",
    "Processes each bit position independently, then combines results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 independent bit-processing modules\n",
    "        self.bit_modules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3, 16),  # 2 input bits + 1 carry-in\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 16),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(64, 5)  # 4 modules \u00d7 16D = 64D\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: [batch, 8] = [a0, a1, a2, a3, b0, b1, b2, b3]\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        bit_outputs = []\n",
    "        carry = torch.zeros(batch_size, 1).to(x.device)\n",
    "        \n",
    "        for i in range(4):\n",
    "            # Get bits for this position\n",
    "            a_bit = x[:, i:i+1]\n",
    "            b_bit = x[:, i+4:i+5]\n",
    "            \n",
    "            # Process with module\n",
    "            module_input = torch.cat([a_bit, b_bit, carry], dim=1)\n",
    "            module_output = self.bit_modules[i](module_input)\n",
    "            bit_outputs.append(module_output)\n",
    "            \n",
    "            # Update carry (simple approximation)\n",
    "            carry = torch.sigmoid(module_output[:, :1])\n",
    "        \n",
    "        # Concatenate all bit module outputs\n",
    "        hidden = torch.cat(bit_outputs, dim=1)  # [batch, 64]\n",
    "        \n",
    "        # Final output\n",
    "        output = torch.sigmoid(self.output(hidden))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "comp_model = CompositionalNetwork().to(device)\n",
    "print(f\"Compositional parameters: {sum(p.numel() for p in comp_model.parameters())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train compositional model\n",
    "print(\"Training Compositional Network...\")\n",
    "comp_losses, comp_accs = train_model(comp_model, train_loader, epochs=100)\n",
    "\n",
    "# Save model\n",
    "torch.save(comp_model.state_dict(), '../models/compositional_4bit.pth')\n",
    "print(f\"\\nFinal accuracy: {comp_accs[-1]:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(mono_losses, label='Monolithic', linewidth=2)\n",
    "ax1.plot(comp_losses, label='Compositional', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training Loss', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2.plot(mono_accs, label='Monolithic', linewidth=2)\n",
    "ax2.plot(comp_accs, label='Compositional', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.set_title('Training Accuracy', fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 105])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Both models achieve 100% accuracy!\")\n",
    "print(\"But do they learn the same representations?\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Save Activations\n",
    "\n",
    "Extract hidden layer activations from both models for Delta Observer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activations\n",
    "mono_model.eval()\n",
    "comp_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    \n",
    "    _, mono_activations = mono_model(X_tensor)\n",
    "    _, comp_activations = comp_model(X_tensor)\n",
    "    \n",
    "    mono_activations = mono_activations.cpu().numpy()\n",
    "    comp_activations = comp_activations.cpu().numpy()\n",
    "\n",
    "print(f\"Monolithic activations: {mono_activations.shape}\")\n",
    "print(f\"Compositional activations: {comp_activations.shape}\")\n",
    "\n",
    "# Save\n",
    "np.savez('../data/monolithic_activations.npz', activations=mono_activations, inputs=X)\n",
    "np.savez('../data/compositional_activations.npz', activations=comp_activations, inputs=X)\n",
    "\n",
    "print(\"\\nActivations saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue to **`02_delta_observer_training.ipynb`** to train the Delta Observer that maps between these representations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}