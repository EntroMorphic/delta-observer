{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† Part 1: Training Source Models\n",
    "\n",
    "This notebook trains two neural networks to solve **4-bit binary addition**:\n",
    "\n",
    "| Model | Architecture | Description |\n",
    "|-------|-------------|-------------|\n",
    "| **Monolithic MLP** | 8 ‚Üí 64 ‚Üí 64 ‚Üí 5 | Single dense network |\n",
    "| **Compositional Network** | Bit-wise modules | Independent bit processing |\n",
    "\n",
    "Both achieve **100% accuracy** but learn fundamentally different internal representations.\n",
    "\n",
    "üìÑ **Paper:** [OSF MetaArXiv](https://doi.org/10.17605/OSF.IO/CNJTP)  \n",
    "üîó **Code:** [github.com/EntroMorphic/delta-observer](https://github.com/EntroMorphic/delta-observer)\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** For the complete Online Delta Observer pipeline (recommended), use **`99_full_reproduction.ipynb`** which trains all models concurrently. This notebook is for understanding the source models in detail.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if needed (Colab)\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_if_needed(package):\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
    "\n",
    "install_if_needed('torch')\n",
    "install_if_needed('matplotlib')\n",
    "\n",
    "print('‚úÖ Dependencies ready!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Device selection\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'üñ•Ô∏è Using device: {device}')\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Colors\n",
    "COLORS = {\n",
    "    'mono': '#e74c3c',    # Red\n",
    "    'comp': '#3498db',    # Blue\n",
    "    'accent': '#2ecc71'   # Green\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create necessary directories\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "print('‚úÖ Directories created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Generate 4-bit Addition Dataset\n",
    "\n",
    "All possible 4-bit + 4-bit additions: **512 examples** (16 √ó 16 combinations)\n",
    "\n",
    "**Key semantic variable:** The number of **carry operations** required (0-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_carries(a, b):\n",
    "    \"\"\"Count the number of carry operations in binary addition.\"\"\"\n",
    "    carries = 0\n",
    "    carry = 0\n",
    "    for i in range(4):\n",
    "        a_bit = (a >> i) & 1\n",
    "        b_bit = (b >> i) & 1\n",
    "        total = a_bit + b_bit + carry\n",
    "        if total >= 2:\n",
    "            carries += 1\n",
    "            carry = 1\n",
    "        else:\n",
    "            carry = 0\n",
    "    return carries\n",
    "\n",
    "def generate_4bit_addition_dataset():\n",
    "    \"\"\"Generate all 512 possible 4-bit + 4-bit additions.\"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    carry_counts = []\n",
    "    \n",
    "    for a in range(16):  # 4-bit: 0-15\n",
    "        for b in range(16):\n",
    "            # Convert to binary (4 bits each)\n",
    "            a_bits = [(a >> i) & 1 for i in range(4)]\n",
    "            b_bits = [(b >> i) & 1 for i in range(4)]\n",
    "            \n",
    "            # Concatenate: [a0, a1, a2, a3, b0, b1, b2, b3]\n",
    "            input_bits = a_bits + b_bits\n",
    "            \n",
    "            # Output: 5-bit sum (0-30)\n",
    "            sum_val = a + b\n",
    "            output_bits = [(sum_val >> i) & 1 for i in range(5)]\n",
    "            \n",
    "            inputs.append(input_bits)\n",
    "            outputs.append(output_bits)\n",
    "            carry_counts.append(count_carries(a, b))\n",
    "    \n",
    "    return (np.array(inputs, dtype=np.float32), \n",
    "            np.array(outputs, dtype=np.float32),\n",
    "            np.array(carry_counts))\n",
    "\n",
    "# Generate dataset\n",
    "X, y, carry_counts = generate_4bit_addition_dataset()\n",
    "print(f'üìä Dataset shape: X={X.shape}, y={y.shape}')\n",
    "print(f'üìä Carry count distribution: {np.bincount(carry_counts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® Visualize the dataset\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Carry count distribution\n",
    "ax1 = axes[0]\n",
    "counts = np.bincount(carry_counts)\n",
    "bars = ax1.bar(range(len(counts)), counts, color=plt.cm.viridis(np.linspace(0, 1, len(counts))),\n",
    "               edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('Carry Count', fontsize=11)\n",
    "ax1.set_ylabel('Number of Examples', fontsize=11)\n",
    "ax1.set_title('üìä Carry Count Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_xticks(range(5))\n",
    "for bar, count in zip(bars, counts):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,\n",
    "             str(count), ha='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Addition heatmap\n",
    "ax2 = axes[1]\n",
    "carry_matrix = np.zeros((16, 16))\n",
    "for a in range(16):\n",
    "    for b in range(16):\n",
    "        carry_matrix[a, b] = count_carries(a, b)\n",
    "im = ax2.imshow(carry_matrix, cmap='viridis', aspect='equal')\n",
    "ax2.set_xlabel('Second Operand (b)', fontsize=11)\n",
    "ax2.set_ylabel('First Operand (a)', fontsize=11)\n",
    "ax2.set_title('üéØ Carries by Operand Pair', fontsize=12, fontweight='bold')\n",
    "plt.colorbar(im, ax=ax2, label='Carry Count')\n",
    "\n",
    "# 3. Example additions\n",
    "ax3 = axes[2]\n",
    "ax3.axis('off')\n",
    "examples = [\n",
    "    (1, 1, '0001 + 0001 = 00010', 0),\n",
    "    (7, 1, '0111 + 0001 = 01000', 3),\n",
    "    (15, 15, '1111 + 1111 = 11110', 4),\n",
    "    (8, 4, '1000 + 0100 = 01100', 0),\n",
    "]\n",
    "text = 'üî¢ Example Additions:\\n\\n'\n",
    "for a, b, binary, carries in examples:\n",
    "    text += f'{a} + {b} = {a+b}\\n'\n",
    "    text += f'  {binary}\\n'\n",
    "    text += f'  Carries: {carries}\\n\\n'\n",
    "ax3.text(0.1, 0.9, text, transform=ax3.transAxes, fontsize=10, \n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "ax3.set_title('üìù Examples', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/dataset_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nüí° The carry count is the key semantic variable we study!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create dataloader\n",
    "dataset = AdditionDataset(X, y)\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "print('‚úÖ DataLoader created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß± Model 1: Monolithic MLP\n",
    "\n",
    "A simple feed-forward network that processes all input bits together.\n",
    "\n",
    "```\n",
    "Input (8) ‚Üí Dense (64) ‚Üí ReLU ‚Üí Dense (64) ‚Üí ReLU ‚Üí Dense (5) ‚Üí Sigmoid\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonolithicMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        hidden = torch.relu(self.fc2(x))  # Extract this layer\n",
    "        x = torch.sigmoid(self.fc3(hidden))\n",
    "        return x, hidden\n",
    "\n",
    "mono_model = MonolithicMLP().to(device)\n",
    "print(f'üß± Monolithic MLP parameters: {sum(p.numel() for p in mono_model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® Visualize architecture\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw layers\n",
    "layer_sizes = [8, 64, 64, 5]\n",
    "layer_names = ['Input\\n(8 bits)', 'Hidden 1\\n(64)', 'Hidden 2\\n(64)', 'Output\\n(5 bits)']\n",
    "layer_colors = ['#3498db', '#e74c3c', '#e74c3c', '#2ecc71']\n",
    "x_positions = [0.1, 0.35, 0.6, 0.85]\n",
    "\n",
    "for i, (x, size, name, color) in enumerate(zip(x_positions, layer_sizes, layer_names, layer_colors)):\n",
    "    # Draw rectangle\n",
    "    height = size / 100\n",
    "    rect = plt.Rectangle((x - 0.08, 0.5 - height/2), 0.16, height,\n",
    "                          facecolor=color, edgecolor='black', linewidth=2, alpha=0.7)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x, 0.5 - height/2 - 0.08, name, ha='center', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Draw arrows\n",
    "    if i < len(x_positions) - 1:\n",
    "        ax.annotate('', xy=(x_positions[i+1] - 0.08, 0.5), xytext=(x + 0.08, 0.5),\n",
    "                    arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "        ax.text((x + x_positions[i+1]) / 2, 0.55, 'Dense\\n+ReLU', ha='center', fontsize=9)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('üß± Monolithic MLP Architecture', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîß Model 2: Compositional Modular Network\n",
    "\n",
    "Processes each bit position independently with separate modules, then combines results.\n",
    "\n",
    "```\n",
    "Bit 0: (a0, b0, carry_in) ‚Üí Module 0 ‚Üí (out0, carry_out)\n",
    "Bit 1: (a1, b1, carry_in) ‚Üí Module 1 ‚Üí (out1, carry_out)\n",
    "...and so on...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompositionalNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 4 independent bit-processing modules\n",
    "        self.bit_modules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3, 16),  # 2 input bits + 1 carry-in\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 16),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(4)\n",
    "        ])\n",
    "        \n",
    "        # Output layer\n",
    "        self.output = nn.Linear(64, 5)  # 4 modules √ó 16D = 64D\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        bit_outputs = []\n",
    "        carry = torch.zeros(batch_size, 1).to(x.device)\n",
    "        \n",
    "        for i in range(4):\n",
    "            # Get bits for this position\n",
    "            a_bit = x[:, i:i+1]\n",
    "            b_bit = x[:, i+4:i+5]\n",
    "            \n",
    "            # Process with module\n",
    "            module_input = torch.cat([a_bit, b_bit, carry], dim=1)\n",
    "            module_output = self.bit_modules[i](module_input)\n",
    "            bit_outputs.append(module_output)\n",
    "            \n",
    "            # Update carry (simple approximation)\n",
    "            carry = torch.sigmoid(module_output[:, :1])\n",
    "        \n",
    "        # Concatenate all bit module outputs\n",
    "        hidden = torch.cat(bit_outputs, dim=1)  # [batch, 64]\n",
    "        \n",
    "        # Final output\n",
    "        output = torch.sigmoid(self.output(hidden))\n",
    "        \n",
    "        return output, hidden\n",
    "\n",
    "comp_model = CompositionalNetwork().to(device)\n",
    "print(f'üîß Compositional Network parameters: {sum(p.numel() for p in comp_model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® Visualize compositional architecture\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.axis('off')\n",
    "\n",
    "# Draw modules\n",
    "module_y = [0.8, 0.6, 0.4, 0.2]\n",
    "module_colors = plt.cm.Blues(np.linspace(0.4, 0.8, 4))\n",
    "\n",
    "for i, (y, color) in enumerate(zip(module_y, module_colors)):\n",
    "    # Input\n",
    "    ax.text(0.05, y, f'a{i}, b{i}', ha='center', fontsize=10, fontweight='bold')\n",
    "    ax.annotate('', xy=(0.15, y), xytext=(0.08, y),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "    \n",
    "    # Module box\n",
    "    rect = plt.Rectangle((0.15, y - 0.06), 0.25, 0.12,\n",
    "                          facecolor=color, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(0.275, y, f'Module {i}\\n(3‚Üí16‚Üí16)', ha='center', va='center', fontsize=9, fontweight='bold')\n",
    "    \n",
    "    # Carry arrow (if not first)\n",
    "    if i > 0:\n",
    "        ax.annotate('', xy=(0.15, y + 0.03), xytext=(0.15, module_y[i-1] - 0.08),\n",
    "                    arrowprops=dict(arrowstyle='->', color='orange', lw=1.5, ls='--'))\n",
    "    \n",
    "    # Output arrow\n",
    "    ax.annotate('', xy=(0.5, y), xytext=(0.4, y),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "# Concatenation\n",
    "concat_rect = plt.Rectangle((0.5, 0.15), 0.1, 0.7,\n",
    "                              facecolor='#9b59b6', edgecolor='black', linewidth=2, alpha=0.7)\n",
    "ax.add_patch(concat_rect)\n",
    "ax.text(0.55, 0.5, 'Concat\\n(64D)', ha='center', va='center', fontsize=10, fontweight='bold', color='white')\n",
    "\n",
    "# Output layer\n",
    "ax.annotate('', xy=(0.7, 0.5), xytext=(0.6, 0.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='black', lw=2))\n",
    "output_rect = plt.Rectangle((0.7, 0.35), 0.15, 0.3,\n",
    "                              facecolor='#2ecc71', edgecolor='black', linewidth=2, alpha=0.7)\n",
    "ax.add_patch(output_rect)\n",
    "ax.text(0.775, 0.5, 'Output\\n(5 bits)', ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('üîß Compositional Network Architecture', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Legend\n",
    "ax.text(0.1, 0.05, 'Orange dashed: Carry propagation', fontsize=9, color='orange')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üèãÔ∏è Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, epochs=100, lr=0.001, name='Model'):\n",
    "    \"\"\"Train a model and return loss/accuracy history.\"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc=f'Training {name}')\n",
    "    for epoch in pbar:\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Accuracy: all 5 bits must match\n",
    "            pred_bits = (outputs > 0.5).float()\n",
    "            correct += (pred_bits == targets).all(dim=1).sum().item()\n",
    "            total += inputs.size(0)\n",
    "        \n",
    "        losses.append(epoch_loss / len(train_loader))\n",
    "        accuracies.append(100 * correct / total)\n",
    "        \n",
    "        pbar.set_postfix({'Loss': f'{losses[-1]:.4f}', 'Acc': f'{accuracies[-1]:.1f}%'})\n",
    "    \n",
    "    return losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train monolithic model\n",
    "print('üß± Training Monolithic MLP...')\n",
    "mono_losses, mono_accs = train_model(mono_model, train_loader, epochs=100, name='Monolithic')\n",
    "\n",
    "# Save model\n",
    "torch.save(mono_model.state_dict(), '../models/monolithic_4bit.pth')\n",
    "print(f'\\n‚úÖ Final accuracy: {mono_accs[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train compositional model\n",
    "print('\\nüîß Training Compositional Network...')\n",
    "comp_losses, comp_accs = train_model(comp_model, train_loader, epochs=100, name='Compositional')\n",
    "\n",
    "# Save model\n",
    "torch.save(comp_model.state_dict(), '../models/compositional_4bit.pth')\n",
    "print(f'\\n‚úÖ Final accuracy: {comp_accs[-1]:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà Compare Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(mono_losses, label='Monolithic', color=COLORS['mono'], linewidth=2.5)\n",
    "ax1.plot(comp_losses, label='Compositional', color=COLORS['comp'], linewidth=2.5)\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Loss', fontsize=12)\n",
    "ax1.set_title('üìâ Training Loss', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=11)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curves\n",
    "ax2 = axes[1]\n",
    "ax2.plot(mono_accs, label='Monolithic', color=COLORS['mono'], linewidth=2.5)\n",
    "ax2.plot(comp_accs, label='Compositional', color=COLORS['comp'], linewidth=2.5)\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax2.set_title('üìà Training Accuracy', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 105])\n",
    "ax2.axhline(100, color='green', linestyle='--', alpha=0.5, label='Perfect')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/source_model_training.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('‚úÖ Both models achieve 100% accuracy!')\n",
    "print('‚ùì But do they learn the same internal representations?')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîç Extract and Analyze Activations\n",
    "\n",
    "Let's extract the hidden layer activations and see if they encode the **carry count**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract activations\n",
    "mono_model.eval()\n",
    "comp_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X, dtype=torch.float32).to(device)\n",
    "    \n",
    "    _, mono_activations = mono_model(X_tensor)\n",
    "    _, comp_activations = comp_model(X_tensor)\n",
    "    \n",
    "    mono_activations = mono_activations.cpu().numpy()\n",
    "    comp_activations = comp_activations.cpu().numpy()\n",
    "\n",
    "print(f'üìä Monolithic activations: {mono_activations.shape}')\n",
    "print(f'üìä Compositional activations: {comp_activations.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize activations with PCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for ax, activations, name, color in [\n",
    "    (axes[0], mono_activations, 'Monolithic', COLORS['mono']),\n",
    "    (axes[1], comp_activations, 'Compositional', COLORS['comp'])\n",
    "]:\n",
    "    # PCA projection\n",
    "    pca = PCA(n_components=2)\n",
    "    act_2d = pca.fit_transform(activations)\n",
    "    \n",
    "    # Scatter plot colored by carry count\n",
    "    scatter = ax.scatter(act_2d[:, 0], act_2d[:, 1], c=carry_counts, \n",
    "                         cmap='viridis', s=30, alpha=0.7, edgecolors='white', linewidth=0.3)\n",
    "    \n",
    "    # Compute linear accessibility\n",
    "    reg = LinearRegression().fit(activations, carry_counts)\n",
    "    r2 = r2_score(carry_counts, reg.predict(activations))\n",
    "    \n",
    "    ax.set_xlabel('PC1', fontsize=11)\n",
    "    ax.set_ylabel('PC2', fontsize=11)\n",
    "    ax.set_title(f'{name} Activations\\nR¬≤ (carry) = {r2:.4f}', fontsize=12, fontweight='bold')\n",
    "    \n",
    "plt.colorbar(scatter, ax=axes, label='Carry Count', shrink=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/activation_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print('\\nüí° Both models encode carry count information, but with different geometries!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save activations for Delta Observer training\n",
    "np.savez('../data/monolithic_activations.npz', \n",
    "         activations=mono_activations, inputs=X, carry_counts=carry_counts)\n",
    "np.savez('../data/compositional_activations.npz', \n",
    "         activations=comp_activations, inputs=X, carry_counts=carry_counts)\n",
    "\n",
    "print('‚úÖ Activations saved to ../data/')\n",
    "print('   - monolithic_activations.npz')\n",
    "print('   - compositional_activations.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Summary\n",
    "\n",
    "| Model | Architecture | Parameters | Final Accuracy | R¬≤ (Carry) |\n",
    "|-------|-------------|------------|----------------|------------|\n",
    "| **Monolithic** | 8 ‚Üí 64 ‚Üí 64 ‚Üí 5 | ~4,500 | 100% | ~0.85 |\n",
    "| **Compositional** | 4 √ó (3 ‚Üí 16 ‚Üí 16) + output | ~4,800 | 100% | ~0.90 |\n",
    "\n",
    "**Key Observations:**\n",
    "1. Both models achieve perfect accuracy on the task\n",
    "2. Both encode carry count information in their activations\n",
    "3. The internal representations have different geometric structures\n",
    "\n",
    "**Next:** The Delta Observer will learn to map between these different representations, discovering shared semantic structure!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "Continue to **`02_delta_observer_training.ipynb`** to train the Delta Observer that maps between these representations.\n",
    "\n",
    "| Notebook | Description | Colab |\n",
    "|----------|-------------|-------|\n",
    "| **02_delta_observer_training** | Train the Delta Observer | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EntroMorphic/delta-observer/blob/main/notebooks/02_delta_observer_training.ipynb) |\n",
    "| **03_analysis_visualization** | Geometric analysis | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EntroMorphic/delta-observer/blob/main/notebooks/03_analysis_visualization.ipynb) |\n",
    "| **99_full_reproduction** | Complete pipeline | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/EntroMorphic/delta-observer/blob/main/notebooks/99_full_reproduction.ipynb) |\n",
    "\n",
    "---\n",
    "\n",
    "**For Science!** üî¨üåä"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
