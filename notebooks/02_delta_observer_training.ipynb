{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Training the Delta Observer\n",
    "\n",
    "This notebook trains the **Delta Observer** network that learns to map between monolithic and compositional representations.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "Monolithic (64D) \u2500\u2500\u2192 Encoder \u2500\u2500\u2510\n",
    "                                \u251c\u2500\u2500\u2192 Shared Latent (16D) \u2500\u2500\u2192 Decoders\n",
    "Compositional (64D) \u2500\u2192 Encoder \u2500\u2500\u2518\n",
    "```\n",
    "\n",
    "The 16D latent space learns the **semantic primitive** that distinguishes these representations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Activations and Prepare Dataset\n",
    "\n",
    "Load activations from both models and compute semantic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load activations with smart path detection\n",
    "import os\n",
    "\n",
    "# Try multiple paths (Colab vs local)\n",
    "paths = ['../data', 'data', 'delta-observer/data']\n",
    "data_dir = next((p for p in paths if os.path.exists(os.path.join(p, 'monolithic_activations.npz'))), None)\n",
    "\n",
    "if not data_dir:\n",
    "    raise FileNotFoundError('Activation data not found. Please run notebook 01 first to generate the data files.')\n",
    "\n",
    "print(f'\u2713 Loading data from: {data_dir}')\n",
    "\n",
    "mono_data = np.load(os.path.join(data_dir, 'monolithic_activations.npz'))\n",
    "comp_data = np.load(os.path.join(data_dir, 'compositional_activations.npz'))\n",
    "\n",
    "mono_activations = mono_data['layer3_post']  # Use final layer activations\n",
    "comp_activations = comp_data['bit3_layer2_post']  # Use bit 3 final layer (16D)\n",
    "inputs = mono_data['inputs']\n",
    "\n",
    "print(f'Monolithic activations: {mono_activations.shape}')\n",
    "print(f'Compositional activations: {comp_activations.shape}')\n",
    "print(f'Inputs: {inputs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute semantic labels\n",
    "def compute_carry_count(input_bits):\n",
    "    \"\"\"Count number of carry operations in 4-bit addition.\"\"\"\n",
    "    carry_count = 0\n",
    "    carry = 0\n",
    "    for i in range(4):\n",
    "        bit_sum = int(input_bits[i]) + int(input_bits[i+4]) + carry\n",
    "        if bit_sum >= 2:\n",
    "            carry_count += 1\n",
    "            carry = 1\n",
    "        else:\n",
    "            carry = 0\n",
    "    return carry_count\n",
    "\n",
    "def compute_bit_position(input_bits):\n",
    "    \"\"\"Determine which bit position has the first carry.\"\"\"\n",
    "    carry = 0\n",
    "    for i in range(4):\n",
    "        bit_sum = int(input_bits[i]) + int(input_bits[i+4]) + carry\n",
    "        if bit_sum >= 2:\n",
    "            return i\n",
    "        carry = 1 if bit_sum >= 2 else 0\n",
    "    return 0\n",
    "\n",
    "# Compute labels\n",
    "carry_counts = np.array([compute_carry_count(inp) for inp in inputs])\n",
    "bit_positions = np.array([compute_bit_position(inp) for inp in inputs])\n",
    "\n",
    "print(f\"\\nCarry count distribution: {np.bincount(carry_counts)}\")\n",
    "print(f\"Bit position distribution: {np.bincount(bit_positions)}\")\n",
    "\n",
    "# Save complete dataset\n",
    "np.savez('../data/delta_observer_dataset.npz',\n",
    "         mono_activations=mono_activations,\n",
    "         comp_activations=comp_activations,\n",
    "         inputs=inputs,\n",
    "         carry_counts=carry_counts,\n",
    "         bit_positions=bit_positions)\n",
    "\n",
    "print(\"\\nDataset saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaObserverDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        data = np.load(data_path)\n",
    "        self.mono_act = torch.tensor(data['mono_activations'], dtype=torch.float32)\n",
    "        self.comp_act = torch.tensor(data['comp_activations'], dtype=torch.float32)\n",
    "        self.carry_counts = torch.tensor(data['carry_counts'], dtype=torch.long)\n",
    "        self.bit_positions = torch.tensor(data['bit_positions'], dtype=torch.long)\n",
    "        self.inputs = torch.tensor(data['inputs'], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.mono_act)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'mono_act': self.mono_act[idx],\n",
    "            'comp_act': self.comp_act[idx],\n",
    "            'carry_count': self.carry_counts[idx],\n",
    "            'bit_position': self.bit_positions[idx],\n",
    "            'input': self.inputs[idx],\n",
    "        }\n",
    "\n",
    "dataset = DeltaObserverDataset('../data/delta_observer_dataset.npz')\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "\n",
    "# Split 80/20\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delta Observer Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeltaObserver(nn.Module):\n",
    "    def __init__(self, mono_dim=64, comp_dim=64, latent_dim=16):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Dual encoders\n",
    "        self.mono_encoder = nn.Sequential(\n",
    "            nn.Linear(mono_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        \n",
    "        self.comp_encoder = nn.Sequential(\n",
    "            nn.Linear(comp_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "        \n",
    "        # Shared latent encoder\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, latent_dim),\n",
    "        )\n",
    "        \n",
    "        # Decoders\n",
    "        self.mono_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, mono_dim),\n",
    "        )\n",
    "        \n",
    "        self.comp_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, comp_dim),\n",
    "        )\n",
    "        \n",
    "        # Classifiers\n",
    "        self.bit_classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "        )\n",
    "        \n",
    "        self.carry_regressor = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 1),\n",
    "        )\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def encode(self, mono_act, comp_act):\n",
    "        mono_enc = self.mono_encoder(mono_act)\n",
    "        comp_enc = self.comp_encoder(comp_act)\n",
    "        joint = torch.cat([mono_enc, comp_enc], dim=-1)\n",
    "        return self.shared_encoder(joint)\n",
    "    \n",
    "    def forward(self, mono_act, comp_act):\n",
    "        latent = self.encode(mono_act, comp_act)\n",
    "        mono_recon = self.mono_decoder(latent)\n",
    "        comp_recon = self.comp_decoder(latent)\n",
    "        bit_logits = self.bit_classifier(latent)\n",
    "        carry_pred = self.carry_regressor(latent)\n",
    "        \n",
    "        return {\n",
    "            'latent': latent,\n",
    "            'mono_recon': mono_recon,\n",
    "            'comp_recon': comp_recon,\n",
    "            'bit_logits': bit_logits,\n",
    "            'carry_pred': carry_pred,\n",
    "        }\n",
    "\n",
    "model = DeltaObserver(mono_dim=64, comp_dim=16, latent_dim=16).to(device)  # comp_dim=16 for compositional\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Training Delta Observer...\\n\")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        mono_act = batch['mono_act'].to(device)\n",
    "        comp_act = batch['comp_act'].to(device)\n",
    "        bit_position = batch['bit_position'].to(device)\n",
    "        carry_count = batch['carry_count'].to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(mono_act, comp_act)\n",
    "        \n",
    "        # Losses\n",
    "        recon_loss = F.mse_loss(outputs['mono_recon'], mono_act) + F.mse_loss(outputs['comp_recon'], comp_act)\n",
    "        class_loss = F.cross_entropy(outputs['bit_logits'], bit_position)\n",
    "        carry_loss = F.mse_loss(outputs['carry_pred'].squeeze(), carry_count)\n",
    "        \n",
    "        loss = recon_loss + class_loss + 0.1 * carry_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        pred = outputs['bit_logits'].argmax(dim=1)\n",
    "        train_correct += (pred == bit_position).sum().item()\n",
    "        train_total += bit_position.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc = train_correct / train_total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            mono_act = batch['mono_act'].to(device)\n",
    "            comp_act = batch['comp_act'].to(device)\n",
    "            bit_position = batch['bit_position'].to(device)\n",
    "            carry_count = batch['carry_count'].to(device).float()\n",
    "            \n",
    "            outputs = model(mono_act, comp_act)\n",
    "            \n",
    "            recon_loss = F.mse_loss(outputs['mono_recon'], mono_act) + F.mse_loss(outputs['comp_recon'], comp_act)\n",
    "            class_loss = F.cross_entropy(outputs['bit_logits'], bit_position)\n",
    "            carry_loss = F.mse_loss(outputs['carry_pred'].squeeze(), carry_count)\n",
    "            \n",
    "            loss = recon_loss + class_loss + 0.1 * carry_loss\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            pred = outputs['bit_logits'].argmax(dim=1)\n",
    "            val_correct += (pred == bit_position).sum().item()\n",
    "            val_total += bit_position.size(0)\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), '../models/delta_observer_best.pt')\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "print(f\"\\nBest Val Loss: {best_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../models/delta_observer_best.pt'))\n",
    "model.eval()\n",
    "\n",
    "full_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "all_latents = []\n",
    "all_carry = []\n",
    "all_bits = []\n",
    "all_inputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        latent = model.encode(batch['mono_act'].to(device), batch['comp_act'].to(device))\n",
    "        all_latents.append(latent.cpu().numpy())\n",
    "        all_carry.append(batch['carry_count'].numpy())\n",
    "        all_bits.append(batch['bit_position'].numpy())\n",
    "        all_inputs.append(batch['input'].numpy())\n",
    "\n",
    "latent_space = np.concatenate(all_latents)\n",
    "carry_counts = np.concatenate(all_carry)\n",
    "bit_positions = np.concatenate(all_bits)\n",
    "inputs = np.concatenate(all_inputs)\n",
    "\n",
    "np.savez('../data/delta_latent_umap.npz',\n",
    "         latent_space=latent_space,\n",
    "         carry_counts=carry_counts,\n",
    "         bit_positions=bit_positions,\n",
    "         inputs=inputs)\n",
    "\n",
    "print(f\"Latent space: {latent_space.shape}\")\n",
    "print(\"Saved to ../data/delta_latent_umap.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Continue to **`03_analysis_visualization.ipynb`** for geometric analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}