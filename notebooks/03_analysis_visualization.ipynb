{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Geometric Analysis & Visualization\n",
    "\n",
    "This notebook performs deep geometric analysis of the Delta Observer's latent space and generates the figures from the paper.\n",
    "\n",
    "## Key Questions\n",
    "\n",
    "1. **Linear Accessibility:** Can we predict semantic properties (carry count) from latent space using linear models?\n",
    "2. **Geometric Clustering:** Are points with similar semantics clustered together in space?\n",
    "3. **The Paradox:** Can information be linearly accessible WITHOUT geometric clustering?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score, r2_score\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import pearsonr\n",
    "import umap\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Environment ready for analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Latent Space\n",
    "\n",
    "Load the 16D latent representations extracted from the trained Delta Observer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nlatent_umap = data['latent_2d']  # 2D UMAP projection\nbit_positions = data['bit_positions']  # 0-3 bit positions\n\n\n# Setup models directory\npossible_models_dirs = ['../models', 'models', 'delta-observer/models']\nmodels_dir = None\nfor p_model in possible_models_dirs:\n    if os.path.exists(p_model):\n        models_dir = p_model\n        break\nif not models_dir:\n    models_dir = '../models'\nos.makedirs(models_dir, exist_ok=True)\nprint(f'\u2713 Models directory: {models_dir}')\n\n# Note: 'inputs' not available in this dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "### PCA: Variance Analysis\n",
    "\n",
    "PCA reveals how much information is captured in the first few dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA analysis\npca = PCA()\nlatent_pca = pca.fit_transform(latent_space)\nexplained_var = pca.explained_variance_ratio_\n\nprint(\"PCA Variance Explained:\")\nprint(f\"  PC1: {explained_var[0]:.2%}\")\nprint(f\"  PC2: {explained_var[1]:.2%}\")\nprint(f\"  PC1+PC2: {explained_var[:2].sum():.2%}\")\nprint(f\"  Top 3: {explained_var[:3].sum():.2%}\")\nprint(f\"  Top 5: {explained_var[:5].sum():.2%}\")\n\n# Visualize variance\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Scree plot\nax1.bar(range(1, len(explained_var)+1), explained_var, alpha=0.7)\nax1.set_xlabel('Principal Component')\nax1.set_ylabel('Variance Explained')\nax1.set_title('PCA Scree Plot', fontweight='bold')\nax1.grid(True, alpha=0.3)\n\n# Cumulative variance\ncumsum_var = np.cumsum(explained_var)\nax2.plot(range(1, len(cumsum_var)+1), cumsum_var, 'o-', linewidth=2)\nax2.axhline(0.95, color='r', linestyle='--', label='95% threshold')\nax2.set_xlabel('Number of Components')\nax2.set_ylabel('Cumulative Variance Explained')\nax2.set_title('Cumulative Variance', fontweight='bold')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'pca_variance.png'), dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\n\u2705 The latent space is relatively low-dimensional:\")\nprint(f\"   {np.argmax(cumsum_var > 0.95) + 1} components explain 95% of variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP: Nonlinear Projection\n",
    "\n",
    "UMAP preserves local structure better than PCA for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UMAP projection\n",
    "print(\"Computing UMAP projection...\")\n",
    "reducer = umap.UMAP(\n",
    "    n_components=2,\n",
    "    n_neighbors=15,\n",
    "    min_dist=0.1,\n",
    "    metric='euclidean',\n",
    "    random_state=42\n",
    ")\n",
    "latent_umap = reducer.fit_transform(latent_space)\n",
    "print(\"\u2705 UMAP complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric 1: Linear Accessibility (R\u00b2)\n",
    "\n",
    "**Question:** Can we predict carry count from latent space using a linear model?\n",
    "\n",
    "**Method:** Train Ridge regression to predict carry count, measure R\u00b2.\n",
    "\n",
    "**Interpretation:**\n",
    "- R\u00b2 \u2248 1: Perfect linear accessibility\n",
    "- R\u00b2 \u2248 0: No linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    latent_space, carry_counts, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train linear probe\n",
    "probe = Ridge(alpha=1.0)\n",
    "probe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train = probe.predict(X_train)\n",
    "y_pred_test = probe.predict(X_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "corr_test, _ = pearsonr(y_test, y_pred_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"LINEAR ACCESSIBILITY ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTrain R\u00b2: {r2_train:.4f}\")\n",
    "print(f\"Test R\u00b2:  {r2_test:.4f}\")\n",
    "print(f\"Test Correlation: {corr_test:.4f}\")\n",
    "print(f\"\\nInterpretation: {r2_test:.1%} of carry count variance\")\n",
    "print(f\"is explained by a LINEAR model of the latent space.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n\n# Scatter plot\nax1.scatter(y_test, y_pred_test, alpha=0.6, s=50)\nax1.plot([0, 4], [0, 4], 'r--', linewidth=2, label='Perfect prediction')\nax1.set_xlabel('True Carry Count', fontsize=12)\nax1.set_ylabel('Predicted Carry Count', fontsize=12)\nax1.set_title(f'Linear Probe Performance (R\u00b2 = {r2_test:.4f})', fontweight='bold')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Residuals\nresiduals = y_test - y_pred_test\nax2.scatter(y_pred_test, residuals, alpha=0.6, s=50)\nax2.axhline(0, color='r', linestyle='--', linewidth=2)\nax2.set_xlabel('Predicted Carry Count', fontsize=12)\nax2.set_ylabel('Residual', fontsize=12)\nax2.set_title('Residual Plot', fontweight='bold')\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'linear_probe_analysis.png'), dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric 2: Geometric Clustering (Silhouette)\n",
    "\n",
    "**Question:** Are points with similar carry counts clustered together in space?\n",
    "\n",
    "**Method:** Compute Silhouette score using carry count as cluster labels.\n",
    "\n",
    "**Interpretation:**\n",
    "- Silhouette \u2248 1: Well-separated clusters\n",
    "- Silhouette \u2248 0: Overlapping, continuous distribution\n",
    "- Silhouette < 0: Points assigned to wrong clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute silhouette scores\n",
    "sil_carry = silhouette_score(latent_space, carry_counts)\n",
    "sil_bit = silhouette_score(latent_space, bit_positions)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"GEOMETRIC CLUSTERING ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSilhouette (carry count):    {sil_carry:.4f}\")\n",
    "print(f\"Silhouette (bit position):   {sil_bit:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "if sil_carry > 0.5:\n",
    "    print(\"  Strong clustering - discrete semantic groups\")\n",
    "elif sil_carry > 0.3:\n",
    "    print(\"  Moderate clustering - some separation\")\n",
    "else:\n",
    "    print(\"  Weak clustering - continuous distribution\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering quality\nfrom sklearn.metrics import silhouette_samples\n\n# Compute per-sample silhouette scores\nsample_silhouette_values = silhouette_samples(latent_space, carry_counts)\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\ny_lower = 10\nfor i in range(5):  # 0-4 carry counts\n    # Get silhouette scores for this cluster\n    ith_cluster_silhouette_values = sample_silhouette_values[carry_counts == i]\n    ith_cluster_silhouette_values.sort()\n    \n    size_cluster_i = ith_cluster_silhouette_values.shape[0]\n    y_upper = y_lower + size_cluster_i\n    \n    color = plt.cm.viridis(float(i) / 5)\n    ax.fill_betweenx(np.arange(y_lower, y_upper),\n                      0, ith_cluster_silhouette_values,\n                      facecolor=color, edgecolor=color, alpha=0.7)\n    \n    # Label the silhouette plots with their cluster numbers at the middle\n    ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n    \n    y_lower = y_upper + 10\n\nax.set_title('Silhouette Analysis by Carry Count', fontweight='bold')\nax.set_xlabel('Silhouette Coefficient')\nax.set_ylabel('Carry Count')\nax.axvline(x=sil_carry, color=\"red\", linestyle=\"--\", label=f'Average: {sil_carry:.3f}')\nax.axvline(x=0, color=\"black\", linestyle=\"-\", linewidth=0.5)\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'silhouette_analysis.png'), dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Paradox Visualization\n",
    "\n",
    "**High R\u00b2 + Low Silhouette = Continuous Semantic Gradients**\n",
    "\n",
    "This is the core finding of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create paradox visualization\nfig, ax = plt.subplots(figsize=(10, 6))\n\nmetrics = ['Linear\\nAccessibility\\n(R\u00b2)', 'Geometric\\nClustering\\n(Silhouette)']\nvalues = [r2_test, sil_carry]\ncolors = ['#2ecc71' if v > 0.5 else '#e74c3c' for v in values]\n\nbars = ax.barh(metrics, values, color=colors, alpha=0.7, height=0.6)\nax.set_xlim(0, 1)\nax.set_xlabel('Score', fontsize=13)\nax.set_title('The Accessibility-Clustering Paradox', fontsize=15, fontweight='bold')\nax.axvline(0.5, color='gray', linestyle='--', alpha=0.5, linewidth=2, label='Threshold (0.5)')\n\n# Add value labels\nfor i, (bar, val) in enumerate(zip(bars, values)):\n    ax.text(val + 0.02, i, f'{val:.4f}', va='center', fontweight='bold', fontsize=12)\n\n# Add interpretation box\ntextstr = '\\n'.join([\n    'HIGH Linear Accessibility:',\n    '  \u2192 Semantic info is linearly decodable',\n    '',\n    'LOW Geometric Clustering:',\n    '  \u2192 NOT organized into discrete clusters',\n    '',\n    'Conclusion: Continuous semantic gradients',\n])\nprops = dict(boxstyle='round', facecolor='wheat', alpha=0.3)\nax.text(0.98, 0.97, textstr, transform=ax.transAxes, fontsize=10,\n        verticalalignment='top', horizontalalignment='right', bbox=props)\n\nax.legend(loc='lower right')\nax.grid(True, alpha=0.3, axis='x')\n\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'accessibility_clustering_paradox.png'), dpi=200, bbox_inches='tight')\nplt.show()\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"THE PARADOX\")\nprint(\"=\"*70)\nprint(f\"Linear Accessibility (R\u00b2): {r2_test:.4f} \u2192 HIGH\")\nprint(f\"Geometric Clustering (Sil): {sil_carry:.4f} \u2192 LOW\")\nprint(\"\\nSemantic information is LINEARLY ACCESSIBLE\")\nprint(\"without requiring GEOMETRIC CLUSTERING.\")\nprint(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Visualizations\n",
    "\n",
    "Visualize the latent space colored by different semantic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\nfig, axes = plt.subplots(2, 3, figsize=(18, 12))\n\n# 1. PCA - Carry count\nax = axes[0, 0]\nscatter = ax.scatter(latent_pca[:, 0], latent_pca[:, 1], \n                     c=carry_counts, cmap='viridis', s=30, alpha=0.6)\nax.set_title('PCA: Carry Count', fontsize=13, fontweight='bold')\nax.set_xlabel(f'PC1 ({explained_var[0]:.1%})')\nax.set_ylabel(f'PC2 ({explained_var[1]:.1%})')\nplt.colorbar(scatter, ax=ax, label='Carry Count')\nax.grid(True, alpha=0.3)\n\n# 2. PCA - Bit position\nax = axes[0, 1]\nscatter = ax.scatter(latent_pca[:, 0], latent_pca[:, 1], \n                     c=bit_positions, cmap='plasma', s=30, alpha=0.6)\nax.set_title('PCA: Bit Position', fontsize=13, fontweight='bold')\nax.set_xlabel(f'PC1 ({explained_var[0]:.1%})')\nax.set_ylabel(f'PC2 ({explained_var[1]:.1%})')\nplt.colorbar(scatter, ax=ax, label='Bit Position')\nax.grid(True, alpha=0.3)\n\n# 3. PCA - Input sum (data not available)\nax = axes[0, 2]\nax.text(0.5, 0.5, 'Input data\\nnot available', ha='center', va='center', fontsize=14, transform=ax.transAxes)\nax.set_title('PCA: Input Sum', fontsize=13, fontweight='bold')\nax.axis('off')\n\n# 4. UMAP - Carry count\nax = axes[1, 0]\nscatter = ax.scatter(latent_umap[:, 0], latent_umap[:, 1], \n                     c=carry_counts, cmap='viridis', s=30, alpha=0.6)\nax.set_title('UMAP: Carry Count', fontsize=13, fontweight='bold')\nax.set_xlabel('UMAP 1')\nax.set_ylabel('UMAP 2')\nplt.colorbar(scatter, ax=ax, label='Carry Count')\nax.grid(True, alpha=0.3)\n\n# 5. UMAP - Bit position\nax = axes[1, 1]\nscatter = ax.scatter(latent_umap[:, 0], latent_umap[:, 1], \n                     c=bit_positions, cmap='plasma', s=30, alpha=0.6)\nax.set_title('UMAP: Bit Position', fontsize=13, fontweight='bold')\nax.set_xlabel('UMAP 1')\nax.set_ylabel('UMAP 2')\nplt.colorbar(scatter, ax=ax, label='Bit Position')\nax.grid(True, alpha=0.3)\n\n# 6. UMAP - Input sum (data not available)\nax = axes[1, 2]\nax.text(0.5, 0.5, 'Input data\\nnot available', ha='center', va='center', fontsize=14, transform=ax.transAxes)\nax.set_title('UMAP: Input Sum', fontsize=13, fontweight='bold')\nax.axis('off')\n\nplt.suptitle('Delta Observer Latent Space: Multiple Perspectives', \n             fontsize=16, fontweight='bold', y=1.00)\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'latent_space_comprehensive.png'), dpi=200, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbation Stability Analysis\n",
    "\n",
    "Test whether the latent space is robust to small perturbations in the input activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate perturbations\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\n# Load model\nsys.path.append(models_dir)  # Add models directory to path for delta_observer.py\nfrom delta_observer import DeltaObserver, DeltaObserverDataset\n\nmodel = DeltaObserver(mono_dim=64, comp_dim=64, latent_dim=16)\nmodel.load_state_dict(torch.load(os.path.join(models_dir, 'delta_observer_best.pt')))\nmodel.eval()\n\ndataset = DeltaObserverDataset(os.path.join(data_dir, 'delta_observer_dataset.npz'))\n\nprint(\"Testing perturbation stability...\")\n\nperturbation_distances = []\nn_samples = 100\n\nwith torch.no_grad():\n    for i in range(min(n_samples, len(dataset))):\n        sample = dataset[i]\n        mono_act = sample['mono_act'].unsqueeze(0)\n        comp_act = sample['comp_act'].unsqueeze(0)\n        \n        # Original latent\n        latent_orig = model.encode(mono_act, comp_act).numpy()\n        \n        # Perturb activations\n        mono_perturbed = mono_act + torch.randn_like(mono_act) * 0.1\n        comp_perturbed = comp_act + torch.randn_like(comp_act) * 0.1\n        \n        # Perturbed latent\n        latent_perturbed = model.encode(mono_perturbed, comp_perturbed).numpy()\n        \n        # Measure distance\n        dist = np.linalg.norm(latent_orig - latent_perturbed)\n        perturbation_distances.append(dist)\n\nmean_dist = np.mean(perturbation_distances)\nstd_dist = np.std(perturbation_distances)\n\nprint(f\"\\nMean perturbation distance: {mean_dist:.4f} \u00b1 {std_dist:.4f}\")\nprint(f\"Interpretation: {'Stable' if mean_dist < 1.0 else 'Unstable'} latent space\")\n\n# Visualize\nplt.figure(figsize=(10, 5))\nplt.hist(perturbation_distances, bins=30, alpha=0.7, edgecolor='black')\nplt.axvline(mean_dist, color='r', linestyle='--', linewidth=2, label=f'Mean: {mean_dist:.3f}')\nplt.xlabel('Perturbation Distance')\nplt.ylabel('Frequency')\nplt.title('Latent Space Stability Under Perturbation', fontweight='bold')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(os.path.join(figures_dir, 'perturbation_stability.png'), dpi=150, bbox_inches='tight')\nplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DELTA OBSERVER: ANALYSIS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\ud83d\udcca DIMENSIONALITY\")\n",
    "print(f\"  Latent space: 16D\")\n",
    "print(f\"  PCA (2 components): {explained_var[:2].sum():.1%} variance\")\n",
    "print(f\"  PCA (5 components): {explained_var[:5].sum():.1%} variance\")\n",
    "\n",
    "print(\"\\n\ud83c\udfaf LINEAR ACCESSIBILITY (R\u00b2)\")\n",
    "print(f\"  Train: {r2_train:.4f}\")\n",
    "print(f\"  Test:  {r2_test:.4f}\")\n",
    "print(f\"  \u2192 Semantic information is LINEARLY ACCESSIBLE\")\n",
    "\n",
    "print(\"\\n\ud83d\udcd0 GEOMETRIC CLUSTERING (Silhouette)\")\n",
    "print(f\"  Carry count: {sil_carry:.4f}\")\n",
    "print(f\"  Bit position: {sil_bit:.4f}\")\n",
    "print(f\"  \u2192 Minimal clustering, CONTINUOUS distribution\")\n",
    "\n",
    "print(\"\\n\ud83d\udd2c PERTURBATION STABILITY\")\n",
    "print(f\"  Mean distance: {mean_dist:.4f} \u00b1 {std_dist:.4f}\")\n",
    "print(f\"  \u2192 {'Stable' if mean_dist < 1.0 else 'Unstable'} representations\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDING: THE ACCESSIBILITY-CLUSTERING PARADOX\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nSemantic information can be LINEARLY ACCESSIBLE (R\u00b2 \u2248 0.95)\")\n",
    "print(\"WITHOUT exhibiting GEOMETRIC CLUSTERING (Silhouette \u2248 0.03).\")\n",
    "print(\"\\nThis challenges the assumption that interpretability requires\")\n",
    "print(\"discrete, spatially separated feature clusters.\")\n",
    "print(\"\\nInstead, semantic primitives exist as CONTINUOUS GRADIENTS.\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n\ud83d\udcc1 Figures saved:\")\n",
    "print(\"  - pca_variance.png\")\n",
    "print(\"  - linear_probe_analysis.png\")\n",
    "print(\"  - silhouette_analysis.png\")\n",
    "print(\"  - accessibility_clustering_paradox.png\")\n",
    "print(\"  - latent_space_comprehensive.png\")\n",
    "print(\"  - perturbation_stability.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "For complete end-to-end reproduction, see **`99_full_reproduction.ipynb`**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}