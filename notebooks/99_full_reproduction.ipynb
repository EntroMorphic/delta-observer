{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete End-to-End Reproduction\n",
    "\n",
    "This notebook reproduces all results from the paper:\n",
    "\n",
    "> **\"Delta Observer: Learning Continuous Semantic Manifolds Between Neural Network Representations\"**  \n",
    "> Aaron (Tripp) Josserand-Austin | EntroMorphic Research Team  \n",
    "> [OSF MetaArXiv](https://doi.org/10.17605/OSF.IO/CNJTP)\n",
    "\n",
    "---\n",
    "\n",
    "## Key Discovery: Transient Clustering\n",
    "\n",
    "**Clustering is scaffolding, not structure.** Networks build geometric organization to *learn* semantic concepts, then discard that organization once the concepts are encoded in the weights.\n",
    "\n",
    "| Training Phase | RÂ² | Silhouette | Interpretation |\n",
    "|----------------|-----|-----------|----------------|\n",
    "| Early (epoch 0) | 0.36 | -0.02 | Random initialization |\n",
    "| Learning (epoch 20) | 0.94 | **0.33** | Clustering emerges |\n",
    "| Final (epoch 200) | 0.99 | -0.02 | Clustering dissolves |\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "1. **Generate Dataset** - All 512 possible 4-bit + 4-bit additions\n",
    "2. **Online Training** - Train all three models concurrently (Monolithic, Compositional, Delta Observer)\n",
    "3. **Trajectory Analysis** - Track RÂ² and Silhouette during training\n",
    "4. **Discover Transient Clustering** - Observe clustering emerge then dissolve\n",
    "5. **Generate Figures** - Reproduce paper visualizations\n",
    "\n",
    "**Estimated runtime:** ~15 minutes on CPU, ~5 minutes on GPU\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import silhouette_score, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Try UMAP, fall back to PCA\n",
    "try:\n",
    "    from umap import UMAP\n",
    "    HAS_UMAP = True\n",
    "except ImportError:\n",
    "    HAS_UMAP = False\n",
    "    print(\"UMAP not available, using PCA for visualization\")\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "RANDOM_SEED = 42\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.001\n",
    "LATENT_DIM = 16\n",
    "SNAPSHOT_INTERVAL = 5  # Save latent space every N epochs\n",
    "\n",
    "# Set seeds\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "# Create directories\n",
    "os.makedirs('../data', exist_ok=True)\n",
    "os.makedirs('../figures', exist_ok=True)\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"ðŸ–¥ï¸  Device: {DEVICE}\")\n",
    "print(f\"ðŸ”„ Training for {EPOCHS} epochs\")\n",
    "print(f\"ðŸ“¸ Snapshot interval: every {SNAPSHOT_INTERVAL} epochs\")\n",
    "print(\"âœ… Configuration complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Generate 4-bit Addition Dataset\n",
    "\n",
    "We generate all 512 possible 4-bit + 4-bit additions. The key semantic variable is **carry count** (0-4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_4bit_addition_dataset():\n",
    "    \"\"\"Generate all 512 possible 4-bit + 4-bit additions.\"\"\"\n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    carry_counts = []\n",
    "    a_values = []\n",
    "    b_values = []\n",
    "    \n",
    "    for a in range(16):\n",
    "        for b in range(16):\n",
    "            # Input: [a0, a1, a2, a3, b0, b1, b2, b3]\n",
    "            a_bits = [(a >> i) & 1 for i in range(4)]\n",
    "            b_bits = [(b >> i) & 1 for i in range(4)]\n",
    "            input_bits = a_bits + b_bits\n",
    "            \n",
    "            # Output: 5-bit sum\n",
    "            sum_val = a + b\n",
    "            output_bits = [(sum_val >> i) & 1 for i in range(5)]\n",
    "            \n",
    "            # Carry count\n",
    "            carry = 0\n",
    "            count = 0\n",
    "            for i in range(4):\n",
    "                bit_sum = a_bits[i] + b_bits[i] + carry\n",
    "                if bit_sum >= 2:\n",
    "                    count += 1\n",
    "                    carry = 1\n",
    "                else:\n",
    "                    carry = 0\n",
    "            \n",
    "            inputs.append(input_bits)\n",
    "            outputs.append(output_bits)\n",
    "            carry_counts.append(count)\n",
    "            a_values.append(a)\n",
    "            b_values.append(b)\n",
    "    \n",
    "    return (np.array(inputs, dtype=np.float32), \n",
    "            np.array(outputs, dtype=np.float32),\n",
    "            np.array(carry_counts, dtype=np.int64),\n",
    "            np.array(a_values),\n",
    "            np.array(b_values))\n",
    "\n",
    "X, y, carry_counts, a_vals, b_vals = generate_4bit_addition_dataset()\n",
    "print(f\"ðŸ“Š Dataset: {X.shape[0]} examples\")\n",
    "print(f\"ðŸ“¥ Input: {X.shape[1]} bits, Output: {y.shape[1]} bits\")\n",
    "print(f\"ðŸ”¢ Carry count distribution: {np.bincount(carry_counts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 5))\n",
    "gs = GridSpec(1, 3, width_ratios=[1, 1.2, 1])\n",
    "\n",
    "# 1. Carry count distribution\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "counts = np.bincount(carry_counts)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 5))\n",
    "bars = ax1.bar(range(5), counts, color=colors, edgecolor='black', linewidth=1.5)\n",
    "ax1.set_xlabel('Carry Count', fontsize=12)\n",
    "ax1.set_ylabel('Number of Examples', fontsize=12)\n",
    "ax1.set_title('Carry Count Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(5))\n",
    "for i, (bar, count) in enumerate(zip(bars, counts)):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 3, \n",
    "             str(count), ha='center', fontsize=11, fontweight='bold')\n",
    "\n",
    "# 2. Carry count heatmap (a vs b)\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "carry_matrix = carry_counts.reshape(16, 16)\n",
    "im = ax2.imshow(carry_matrix, cmap='viridis', origin='lower')\n",
    "ax2.set_xlabel('b (second operand)', fontsize=12)\n",
    "ax2.set_ylabel('a (first operand)', fontsize=12)\n",
    "ax2.set_title('Carry Count by Operands', fontsize=14, fontweight='bold')\n",
    "ax2.set_xticks([0, 5, 10, 15])\n",
    "ax2.set_yticks([0, 5, 10, 15])\n",
    "cbar = plt.colorbar(im, ax=ax2, label='Carry Count')\n",
    "cbar.set_ticks([0, 1, 2, 3, 4])\n",
    "\n",
    "# 3. Example additions\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Example Additions', fontsize=14, fontweight='bold')\n",
    "\n",
    "examples = [\n",
    "    (3, 2, '0011 + 0010 = 00101', 0),   # 3+2=5, no carries\n",
    "    (7, 1, '0111 + 0001 = 01000', 3),   # 7+1=8, 3 carries\n",
    "    (15, 15, '1111 + 1111 = 11110', 4), # 15+15=30, 4 carries\n",
    "    (8, 4, '1000 + 0100 = 01100', 0),   # 8+4=12, no carries\n",
    "    (9, 7, '1001 + 0111 = 10000', 4),   # 9+7=16, 4 carries\n",
    "]\n",
    "\n",
    "text = \"   a  +  b  =  sum   carries\\n\" + \"â”€\"*35 + \"\\n\"\n",
    "for a, b, desc, c in examples:\n",
    "    text += f\"  {a:2d} + {b:2d} = {a+b:2d}    ({c} carries)\\n\"\n",
    "    text += f\"  {desc}\\n\\n\"\n",
    "\n",
    "ax3.text(0.1, 0.95, text, transform=ax3.transAxes, fontsize=10,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/dataset_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Dataset visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdditionDataset(Dataset):\n",
    "    def __init__(self, X, y, carry_counts):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        self.carry_counts = torch.tensor(carry_counts, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.carry_counts[idx]\n",
    "\n",
    "dataset = AdditionDataset(X, y, carry_counts)\n",
    "train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "full_loader = DataLoader(dataset, batch_size=512, shuffle=False)\n",
    "print(\"âœ… Dataset ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Model Architectures\n",
    "\n",
    "We use two contrasting architectures:\n",
    "- **Monolithic MLP**: Processes all 8 input bits together\n",
    "- **Compositional Network**: Processes each bit position separately with carry propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonolithicMLP(nn.Module):\n",
    "    \"\"\"Standard MLP that processes all bits at once.\"\"\"\n",
    "    def __init__(self, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 5)\n",
    "        self.hidden_dim = hidden_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        hidden = torch.relu(self.fc2(x))\n",
    "        out = torch.sigmoid(self.fc3(hidden))\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "class CompositionalNetwork(nn.Module):\n",
    "    \"\"\"Modular network with separate per-bit processing.\"\"\"\n",
    "    def __init__(self, module_dim=16):\n",
    "        super().__init__()\n",
    "        self.bit_modules = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(3, module_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(module_dim, module_dim),\n",
    "                nn.ReLU()\n",
    "            ) for _ in range(4)\n",
    "        ])\n",
    "        self.output = nn.Linear(4 * module_dim, 5)\n",
    "        self.hidden_dim = 4 * module_dim\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        bit_outputs = []\n",
    "        carry = torch.zeros(batch_size, 1, device=x.device)\n",
    "        \n",
    "        for i in range(4):\n",
    "            a_bit = x[:, i:i+1]\n",
    "            b_bit = x[:, i+4:i+5]\n",
    "            module_input = torch.cat([a_bit, b_bit, carry], dim=1)\n",
    "            module_output = self.bit_modules[i](module_input)\n",
    "            bit_outputs.append(module_output)\n",
    "            carry = torch.sigmoid(module_output[:, :1])\n",
    "        \n",
    "        hidden = torch.cat(bit_outputs, dim=1)\n",
    "        out = torch.sigmoid(self.output(hidden))\n",
    "        return out, hidden\n",
    "\n",
    "\n",
    "class DeltaObserver(nn.Module):\n",
    "    \"\"\"Learns shared latent space between two architectures.\"\"\"\n",
    "    def __init__(self, mono_dim=64, comp_dim=64, latent_dim=16):\n",
    "        super().__init__()\n",
    "        self.mono_encoder = nn.Sequential(\n",
    "            nn.Linear(mono_dim, 32), nn.ReLU(), nn.Dropout(0.1)\n",
    "        )\n",
    "        self.comp_encoder = nn.Sequential(\n",
    "            nn.Linear(comp_dim, 32), nn.ReLU(), nn.Dropout(0.1)\n",
    "        )\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Linear(64, 32), nn.ReLU(), nn.Dropout(0.1),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "        self.mono_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32), nn.ReLU(),\n",
    "            nn.Linear(32, mono_dim)\n",
    "        )\n",
    "        self.comp_decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32), nn.ReLU(),\n",
    "            nn.Linear(32, comp_dim)\n",
    "        )\n",
    "        self.carry_head = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 8), nn.ReLU(),\n",
    "            nn.Linear(8, 1)\n",
    "        )\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def encode(self, mono_act, comp_act):\n",
    "        mono_enc = self.mono_encoder(mono_act)\n",
    "        comp_enc = self.comp_encoder(comp_act)\n",
    "        joint = torch.cat([mono_enc, comp_enc], dim=-1)\n",
    "        return self.shared_encoder(joint)\n",
    "    \n",
    "    def forward(self, mono_act, comp_act):\n",
    "        latent = self.encode(mono_act, comp_act)\n",
    "        return {\n",
    "            'latent': latent,\n",
    "            'mono_recon': self.mono_decoder(latent),\n",
    "            'comp_recon': self.comp_decoder(latent),\n",
    "            'carry_pred': self.carry_head(latent)\n",
    "        }\n",
    "\n",
    "print(\"âœ… Model architectures defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Architecture Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "# Helper function to draw boxes\n",
    "def draw_box(ax, x, y, w, h, text, color='lightblue', fontsize=9):\n",
    "    rect = mpatches.FancyBboxPatch((x, y), w, h, boxstyle=\"round,pad=0.02\",\n",
    "                                    facecolor=color, edgecolor='black', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(x + w/2, y + h/2, text, ha='center', va='center', fontsize=fontsize, fontweight='bold')\n",
    "\n",
    "def draw_arrow(ax, x1, y1, x2, y2):\n",
    "    ax.annotate('', xy=(x2, y2), xytext=(x1, y1),\n",
    "                arrowprops=dict(arrowstyle='->', color='gray', lw=1.5))\n",
    "\n",
    "# 1. Monolithic MLP\n",
    "ax1 = axes[0]\n",
    "ax1.set_xlim(0, 10)\n",
    "ax1.set_ylim(0, 10)\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Monolithic MLP', fontsize=14, fontweight='bold')\n",
    "\n",
    "draw_box(ax1, 3, 8, 4, 1, 'Input (8 bits)', 'lightgreen')\n",
    "draw_arrow(ax1, 5, 8, 5, 7)\n",
    "draw_box(ax1, 2.5, 5.5, 5, 1.2, 'Hidden (64 dim)', 'lightblue')\n",
    "draw_arrow(ax1, 5, 5.5, 5, 4.5)\n",
    "draw_box(ax1, 2.5, 3, 5, 1.2, 'Hidden (64 dim)', 'lightblue')\n",
    "draw_arrow(ax1, 5, 3, 5, 2)\n",
    "draw_box(ax1, 3, 0.5, 4, 1, 'Output (5 bits)', 'lightyellow')\n",
    "ax1.text(5, -0.5, 'All bits processed\\ntogether', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "# 2. Compositional Network\n",
    "ax2 = axes[1]\n",
    "ax2.set_xlim(0, 10)\n",
    "ax2.set_ylim(0, 10)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Compositional Network', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Input bits\n",
    "for i in range(4):\n",
    "    draw_box(ax2, 0.5 + i*2.3, 8, 2, 0.8, f'Bit {i}', 'lightgreen', fontsize=8)\n",
    "\n",
    "# Bit modules\n",
    "for i in range(4):\n",
    "    draw_arrow(ax2, 1.5 + i*2.3, 8, 1.5 + i*2.3, 7)\n",
    "    draw_box(ax2, 0.5 + i*2.3, 5.5, 2, 1.2, f'Module\\n{i}', 'lightcoral', fontsize=8)\n",
    "\n",
    "# Carry arrows\n",
    "for i in range(3):\n",
    "    ax2.annotate('', xy=(2.7 + i*2.3, 6.1), xytext=(2.5 + i*2.3, 6.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "ax2.text(5, 6.9, 'carry propagation â†’', ha='center', fontsize=9, color='red')\n",
    "\n",
    "# Concatenate\n",
    "for i in range(4):\n",
    "    draw_arrow(ax2, 1.5 + i*2.3, 5.5, 5, 4)\n",
    "draw_box(ax2, 2.5, 2.5, 5, 1.2, 'Concat (64 dim)', 'lightblue')\n",
    "draw_arrow(ax2, 5, 2.5, 5, 1.5)\n",
    "draw_box(ax2, 3, 0.3, 4, 0.9, 'Output (5 bits)', 'lightyellow')\n",
    "ax2.text(5, -0.5, 'Each bit position\\nprocessed separately', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "# 3. Delta Observer\n",
    "ax3 = axes[2]\n",
    "ax3.set_xlim(0, 10)\n",
    "ax3.set_ylim(0, 10)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Delta Observer', fontsize=14, fontweight='bold')\n",
    "\n",
    "draw_box(ax3, 0.5, 8, 3.5, 1, 'Mono Hidden', 'lightblue')\n",
    "draw_box(ax3, 6, 8, 3.5, 1, 'Comp Hidden', 'lightcoral')\n",
    "draw_arrow(ax3, 2.25, 8, 3.5, 6.5)\n",
    "draw_arrow(ax3, 7.75, 8, 6.5, 6.5)\n",
    "draw_box(ax3, 2, 5.5, 3, 0.8, 'Encoder', 'plum', fontsize=9)\n",
    "draw_box(ax3, 5, 5.5, 3, 0.8, 'Encoder', 'plum', fontsize=9)\n",
    "draw_arrow(ax3, 3.5, 5.5, 5, 4.5)\n",
    "draw_arrow(ax3, 6.5, 5.5, 5, 4.5)\n",
    "draw_box(ax3, 3, 3.5, 4, 0.9, 'Shared Latent\\n(16 dim)', 'gold', fontsize=9)\n",
    "draw_arrow(ax3, 5, 3.5, 3, 2)\n",
    "draw_arrow(ax3, 5, 3.5, 7, 2)\n",
    "draw_arrow(ax3, 5, 3.5, 5, 1.5)\n",
    "draw_box(ax3, 1.5, 1, 2.5, 0.7, 'Mono\\nRecon', 'lightblue', fontsize=8)\n",
    "draw_box(ax3, 6, 1, 2.5, 0.7, 'Comp\\nRecon', 'lightcoral', fontsize=8)\n",
    "draw_box(ax3, 3.75, 0.3, 2.5, 0.7, 'Carry\\nPred', 'lightgreen', fontsize=8)\n",
    "ax3.text(5, -0.5, 'Maps between\\nrepresentation spaces', ha='center', fontsize=10, style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/architecture_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Architecture visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Online Training (All Models Concurrently)\n",
    "\n",
    "**This is the key innovation.** The Delta Observer watches training as it happens, capturing temporal dynamics invisible to post-hoc analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "mono_model = MonolithicMLP(hidden_dim=64).to(DEVICE)\n",
    "comp_model = CompositionalNetwork(module_dim=16).to(DEVICE)\n",
    "delta_model = DeltaObserver(mono_dim=64, comp_dim=64, latent_dim=LATENT_DIM).to(DEVICE)\n",
    "\n",
    "# Optimizers\n",
    "mono_opt = optim.Adam(mono_model.parameters(), lr=LEARNING_RATE)\n",
    "comp_opt = optim.Adam(comp_model.parameters(), lr=LEARNING_RATE)\n",
    "delta_opt = optim.Adam(delta_model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Trajectory storage\n",
    "trajectory = {\n",
    "    'epochs': [],\n",
    "    'latents': [],\n",
    "    'carry_counts': [],\n",
    "    'mono_acc': [],\n",
    "    'comp_acc': [],\n",
    "    'r2': [],\n",
    "    'silhouette': [],\n",
    "    'mono_loss': [],\n",
    "    'comp_loss': [],\n",
    "    'delta_loss': []\n",
    "}\n",
    "\n",
    "print(\"ðŸ§  Models initialized\")\n",
    "print(f\"   Monolithic: {sum(p.numel() for p in mono_model.parameters()):,} params\")\n",
    "print(f\"   Compositional: {sum(p.numel() for p in comp_model.parameters()):,} params\")\n",
    "print(f\"   Delta Observer: {sum(p.numel() for p in delta_model.parameters()):,} params\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(latents, carry_counts):\n",
    "    \"\"\"Compute RÂ² and Silhouette score.\"\"\"\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(latents, carry_counts)\n",
    "    r2 = r2_score(carry_counts, reg.predict(latents))\n",
    "    \n",
    "    try:\n",
    "        sil = silhouette_score(latents, carry_counts)\n",
    "    except:\n",
    "        sil = 0.0\n",
    "    \n",
    "    return r2, sil\n",
    "\n",
    "\n",
    "def compute_accuracy(model, loader):\n",
    "    \"\"\"Compute model accuracy.\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, _ in loader:\n",
    "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
    "            outputs, _ = model(inputs)\n",
    "            pred_bits = (outputs > 0.5).float()\n",
    "            correct += (pred_bits == targets).all(dim=1).sum().item()\n",
    "            total += inputs.size(0)\n",
    "    return 100 * correct / total\n",
    "\n",
    "\n",
    "def snapshot_latents(mono_model, comp_model, delta_model, loader, device):\n",
    "    \"\"\"Extract latent representations for all samples.\"\"\"\n",
    "    mono_model.eval()\n",
    "    comp_model.eval()\n",
    "    delta_model.eval()\n",
    "    \n",
    "    all_latents = []\n",
    "    all_carry = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, _, carry in loader:\n",
    "            inputs = inputs.to(device)\n",
    "            _, mono_h = mono_model(inputs)\n",
    "            _, comp_h = comp_model(inputs)\n",
    "            latent = delta_model.encode(mono_h, comp_h)\n",
    "            all_latents.append(latent.cpu().numpy())\n",
    "            all_carry.append(carry.numpy())\n",
    "    \n",
    "    return np.concatenate(all_latents), np.concatenate(all_carry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"ðŸš€ ONLINE TRAINING - All models train concurrently\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nThe Delta Observer watches training as it happens...\\n\")\n",
    "\n",
    "epoch_losses = {'mono': [], 'comp': [], 'delta': []}\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS), desc=\"Training\"):\n",
    "    mono_model.train()\n",
    "    comp_model.train()\n",
    "    delta_model.train()\n",
    "    \n",
    "    batch_losses = {'mono': [], 'comp': [], 'delta': []}\n",
    "    \n",
    "    for inputs, targets, carry in train_loader:\n",
    "        inputs = inputs.to(DEVICE)\n",
    "        targets = targets.to(DEVICE)\n",
    "        carry = carry.to(DEVICE).float()\n",
    "        \n",
    "        # --- Train Monolithic ---\n",
    "        mono_opt.zero_grad()\n",
    "        mono_out, mono_h = mono_model(inputs)\n",
    "        mono_loss = criterion(mono_out, targets)\n",
    "        mono_loss.backward()\n",
    "        mono_opt.step()\n",
    "        batch_losses['mono'].append(mono_loss.item())\n",
    "        \n",
    "        # --- Train Compositional ---\n",
    "        comp_opt.zero_grad()\n",
    "        comp_out, comp_h = comp_model(inputs)\n",
    "        comp_loss = criterion(comp_out, targets)\n",
    "        comp_loss.backward()\n",
    "        comp_opt.step()\n",
    "        batch_losses['comp'].append(comp_loss.item())\n",
    "        \n",
    "        # --- Train Delta Observer (detached activations) ---\n",
    "        with torch.no_grad():\n",
    "            _, mono_h_det = mono_model(inputs)\n",
    "            _, comp_h_det = comp_model(inputs)\n",
    "        \n",
    "        delta_opt.zero_grad()\n",
    "        delta_out = delta_model(mono_h_det.detach(), comp_h_det.detach())\n",
    "        \n",
    "        recon_loss = (nn.functional.mse_loss(delta_out['mono_recon'], mono_h_det.detach()) +\n",
    "                      nn.functional.mse_loss(delta_out['comp_recon'], comp_h_det.detach()))\n",
    "        carry_loss = nn.functional.mse_loss(delta_out['carry_pred'].squeeze(), carry)\n",
    "        delta_loss = recon_loss + 0.1 * carry_loss\n",
    "        delta_loss.backward()\n",
    "        delta_opt.step()\n",
    "        batch_losses['delta'].append(delta_loss.item())\n",
    "    \n",
    "    # Store epoch losses\n",
    "    epoch_losses['mono'].append(np.mean(batch_losses['mono']))\n",
    "    epoch_losses['comp'].append(np.mean(batch_losses['comp']))\n",
    "    epoch_losses['delta'].append(np.mean(batch_losses['delta']))\n",
    "    \n",
    "    # --- Snapshot at intervals ---\n",
    "    if epoch % SNAPSHOT_INTERVAL == 0 or epoch == EPOCHS - 1:\n",
    "        latents, carries = snapshot_latents(mono_model, comp_model, delta_model, full_loader, DEVICE)\n",
    "        r2, sil = compute_metrics(latents, carries)\n",
    "        mono_acc = compute_accuracy(mono_model, full_loader)\n",
    "        comp_acc = compute_accuracy(comp_model, full_loader)\n",
    "        \n",
    "        trajectory['epochs'].append(epoch)\n",
    "        trajectory['latents'].append(latents.copy())\n",
    "        trajectory['carry_counts'].append(carries.copy())\n",
    "        trajectory['r2'].append(r2)\n",
    "        trajectory['silhouette'].append(sil)\n",
    "        trajectory['mono_acc'].append(mono_acc)\n",
    "        trajectory['comp_acc'].append(comp_acc)\n",
    "        trajectory['mono_loss'].append(epoch_losses['mono'][-1])\n",
    "        trajectory['comp_loss'].append(epoch_losses['comp'][-1])\n",
    "        trajectory['delta_loss'].append(epoch_losses['delta'][-1])\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            print(f\"\\nEpoch {epoch:3d}: RÂ²={r2:.4f}, Sil={sil:.4f}, Mono={mono_acc:.1f}%, Comp={comp_acc:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Online training complete!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "epochs_arr = np.array(trajectory['epochs'])\n",
    "\n",
    "# 1. Model Accuracy\n",
    "ax1 = axes[0, 0]\n",
    "ax1.plot(epochs_arr, trajectory['mono_acc'], 'b-', linewidth=2, marker='o', markersize=3, label='Monolithic')\n",
    "ax1.plot(epochs_arr, trajectory['comp_acc'], 'r-', linewidth=2, marker='s', markersize=3, label='Compositional')\n",
    "ax1.set_xlabel('Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax1.set_title('Model Accuracy During Training', fontsize=14, fontweight='bold')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_ylim(0, 105)\n",
    "ax1.axhline(y=100, color='green', linestyle='--', alpha=0.3)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Training Loss\n",
    "ax2 = axes[0, 1]\n",
    "ax2.semilogy(range(EPOCHS), epoch_losses['mono'], 'b-', alpha=0.7, label='Monolithic')\n",
    "ax2.semilogy(range(EPOCHS), epoch_losses['comp'], 'r-', alpha=0.7, label='Compositional')\n",
    "ax2.semilogy(range(EPOCHS), epoch_losses['delta'], 'g-', alpha=0.7, label='Delta Observer')\n",
    "ax2.set_xlabel('Epoch', fontsize=12)\n",
    "ax2.set_ylabel('Loss (log scale)', fontsize=12)\n",
    "ax2.set_title('Training Loss', fontsize=14, fontweight='bold')\n",
    "ax2.legend(loc='upper right')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. RÂ² Evolution\n",
    "ax3 = axes[1, 0]\n",
    "ax3.plot(epochs_arr, trajectory['r2'], 'g-', linewidth=2.5, marker='o', markersize=4)\n",
    "ax3.fill_between(epochs_arr, 0, trajectory['r2'], alpha=0.2, color='green')\n",
    "ax3.set_xlabel('Epoch', fontsize=12)\n",
    "ax3.set_ylabel('RÂ² (Linear Accessibility)', fontsize=12)\n",
    "ax3.set_title('Semantic Accessibility During Training', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylim(0, 1.05)\n",
    "ax3.axhline(y=0.9, color='green', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Silhouette Evolution (Transient Clustering)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.plot(epochs_arr, trajectory['silhouette'], 'r-', linewidth=2.5, marker='s', markersize=4)\n",
    "ax4.fill_between(epochs_arr, 0, trajectory['silhouette'], where=np.array(trajectory['silhouette'])>0, \n",
    "                 alpha=0.3, color='red', label='Positive clustering')\n",
    "ax4.fill_between(epochs_arr, 0, trajectory['silhouette'], where=np.array(trajectory['silhouette'])<=0,\n",
    "                 alpha=0.3, color='blue', label='No clustering')\n",
    "peak_idx = np.argmax(trajectory['silhouette'])\n",
    "ax4.annotate(f'Peak: {trajectory[\"silhouette\"][peak_idx]:.2f}', \n",
    "             xy=(epochs_arr[peak_idx], trajectory['silhouette'][peak_idx]),\n",
    "             xytext=(epochs_arr[peak_idx]+30, trajectory['silhouette'][peak_idx]+0.05),\n",
    "             arrowprops=dict(arrowstyle='->', color='red'),\n",
    "             fontsize=10, color='red')\n",
    "ax4.set_xlabel('Epoch', fontsize=12)\n",
    "ax4.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax4.set_title('Geometric Clustering (Transient!)', fontsize=14, fontweight='bold')\n",
    "ax4.axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "ax4.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/training_progress.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Training progress visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Discover Transient Clustering\n",
    "\n",
    "**The key finding:** Clustering peaks during training then dissolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.array(trajectory['epochs'])\n",
    "r2_values = np.array(trajectory['r2'])\n",
    "sil_values = np.array(trajectory['silhouette'])\n",
    "\n",
    "# Find peak clustering\n",
    "peak_idx = np.argmax(sil_values)\n",
    "peak_epoch = epochs[peak_idx]\n",
    "peak_sil = sil_values[peak_idx]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸŽ¯ TRANSIENT CLUSTERING DISCOVERY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nðŸ“ˆ Peak clustering: Silhouette = {peak_sil:.4f} at epoch {peak_epoch}\")\n",
    "print(f\"ðŸ“‰ Final state:     Silhouette = {sil_values[-1]:.4f} at epoch {epochs[-1]}\")\n",
    "print(f\"\\nâœ¨ Final RÂ² (accessibility): {r2_values[-1]:.4f}\")\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"ðŸ’¡ INTERPRETATION\")\n",
    "print(\"-\"*70)\n",
    "print(\"\\n  â€¢ Clustering EMERGES during learning (scaffolding)\")\n",
    "print(\"  â€¢ Clustering DISSOLVES after convergence (scaffolding removed)\")\n",
    "print(\"\\n  â†’ The semantic primitive is in the TRAJECTORY, not the final state.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Latent Space Evolution (Before â†’ During â†’ After Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select three key epochs: early, peak clustering, final\n",
    "early_idx = 0\n",
    "peak_idx = np.argmax(sil_values)\n",
    "final_idx = -1\n",
    "\n",
    "key_epochs = [\n",
    "    (early_idx, 'Early (Random)', epochs[early_idx]),\n",
    "    (peak_idx, 'Peak Clustering', epochs[peak_idx]),\n",
    "    (final_idx, 'Final (Converged)', epochs[final_idx])\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "for ax, (idx, title, ep) in zip(axes, key_epochs):\n",
    "    latents = trajectory['latents'][idx]\n",
    "    carries = trajectory['carry_counts'][idx]\n",
    "    \n",
    "    # Use PCA for consistent comparison\n",
    "    pca = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "    latents_2d = pca.fit_transform(latents)\n",
    "    \n",
    "    r2, sil = compute_metrics(latents, carries)\n",
    "    \n",
    "    scatter = ax.scatter(latents_2d[:, 0], latents_2d[:, 1],\n",
    "                        c=carries, cmap='viridis',\n",
    "                        s=30, alpha=0.7, edgecolors='white', linewidth=0.3)\n",
    "    \n",
    "    ax.set_xlabel('PC1', fontsize=11)\n",
    "    ax.set_ylabel('PC2', fontsize=11)\n",
    "    ax.set_title(f'{title}\\nEpoch {ep}', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    # Metrics box\n",
    "    textstr = f'RÂ² = {r2:.3f}\\nSil = {sil:.3f}'\n",
    "    props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', bbox=props)\n",
    "\n",
    "# Add colorbar to last plot\n",
    "cbar = plt.colorbar(scatter, ax=axes[-1], label='Carry Count')\n",
    "cbar.set_ticks([0, 1, 2, 3, 4])\n",
    "\n",
    "plt.suptitle('Latent Space Evolution: Clustering is Transient', fontsize=15, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/latent_evolution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Latent evolution visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Key Figure: Transient Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: Transient Clustering\n",
    "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "color1 = '#2ecc71'  # Green for RÂ²\n",
    "color2 = '#e74c3c'  # Red for Silhouette\n",
    "\n",
    "ax1.set_xlabel('Training Epoch', fontsize=12)\n",
    "ax1.set_ylabel('RÂ² (Linear Accessibility)', color=color1, fontsize=12)\n",
    "line1, = ax1.plot(epochs, r2_values, color=color1, linewidth=2.5, marker='o', markersize=4, label='RÂ²')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.set_ylim(0, 1.05)\n",
    "ax1.axhline(y=0.9, color=color1, linestyle='--', alpha=0.3)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel('Silhouette Score (Clustering)', color=color2, fontsize=12)\n",
    "line2, = ax2.plot(epochs, sil_values, color=color2, linewidth=2.5, marker='s', markersize=4, label='Silhouette')\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "ax2.set_ylim(-0.1, 0.5)\n",
    "ax2.axhline(y=0, color=color2, linestyle='--', alpha=0.3)\n",
    "\n",
    "# Highlight phases\n",
    "ax1.axvspan(0, 10, alpha=0.1, color='blue', label='Init')\n",
    "ax1.axvspan(10, 50, alpha=0.1, color='green', label='Learning')\n",
    "ax1.axvspan(50, EPOCHS, alpha=0.1, color='orange', label='Converged')\n",
    "\n",
    "# Annotate peak\n",
    "ax2.annotate(f'Peak: {peak_sil:.2f}\\n(epoch {peak_epoch})',\n",
    "             xy=(peak_epoch, peak_sil),\n",
    "             xytext=(peak_epoch + 30, peak_sil + 0.08),\n",
    "             fontsize=10,\n",
    "             arrowprops=dict(arrowstyle='->', color=color2, alpha=0.7),\n",
    "             color=color2)\n",
    "\n",
    "ax1.set_title('Transient Clustering: Scaffolding Emerges Then Dissolves', fontsize=14, fontweight='bold')\n",
    "ax1.legend([line1, line2], ['RÂ² (Accessibility)', 'Silhouette (Clustering)'], loc='center right')\n",
    "\n",
    "# Phase labels\n",
    "ax1.text(5, 0.15, 'Init', ha='center', fontsize=10, color='blue', alpha=0.7)\n",
    "ax1.text(30, 0.15, 'Learning', ha='center', fontsize=10, color='green', alpha=0.7)\n",
    "ax1.text(125, 0.15, 'Converged', ha='center', fontsize=10, color='orange', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/figure5_training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Figure 5 (Training Curves) saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Visualize Final Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final latent space\n",
    "final_latents = trajectory['latents'][-1]\n",
    "final_carry = trajectory['carry_counts'][-1]\n",
    "\n",
    "# Dimensionality reduction\n",
    "if HAS_UMAP:\n",
    "    reducer = UMAP(n_components=2, random_state=RANDOM_SEED, n_neighbors=15, min_dist=0.1)\n",
    "    latents_2d = reducer.fit_transform(final_latents)\n",
    "    method = \"UMAP\"\n",
    "else:\n",
    "    reducer = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "    latents_2d = reducer.fit_transform(final_latents)\n",
    "    method = \"PCA\"\n",
    "\n",
    "# Final metrics\n",
    "final_r2, final_sil = compute_metrics(final_latents, final_carry)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "scatter = ax.scatter(latents_2d[:, 0], latents_2d[:, 1],\n",
    "                     c=final_carry, cmap='viridis',\n",
    "                     s=50, alpha=0.7, edgecolors='white', linewidth=0.5)\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax, label='Carry Count')\n",
    "cbar.set_ticks([0, 1, 2, 3, 4])\n",
    "\n",
    "ax.set_xlabel(f'{method} Dimension 1', fontsize=12)\n",
    "ax.set_ylabel(f'{method} Dimension 2', fontsize=12)\n",
    "ax.set_title('Online Delta Observer Latent Space\\n(Final State)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add metrics\n",
    "textstr = f'RÂ² = {final_r2:.4f}\\nSilhouette = {final_sil:.4f}'\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=11,\n",
    "        verticalalignment='top', bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/figure2_delta_latent_space.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Figure 2 (Latent Space) saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dimension Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze which latent dimensions correlate with carry count\n",
    "correlations = []\n",
    "for i in range(LATENT_DIM):\n",
    "    corr = np.corrcoef(final_latents[:, i], final_carry)[0, 1]\n",
    "    correlations.append(corr)\n",
    "\n",
    "correlations = np.array(correlations)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# 1. Correlation bar chart\n",
    "ax1 = axes[0]\n",
    "colors = ['#e74c3c' if c < 0 else '#2ecc71' for c in correlations]\n",
    "ax1.bar(range(LATENT_DIM), correlations, color=colors, edgecolor='black', linewidth=0.5)\n",
    "ax1.axhline(y=0, color='black', linewidth=0.5)\n",
    "ax1.set_xlabel('Latent Dimension', fontsize=12)\n",
    "ax1.set_ylabel('Correlation with Carry Count', fontsize=12)\n",
    "ax1.set_title('Latent Dimension Correlations', fontsize=14, fontweight='bold')\n",
    "ax1.set_xticks(range(LATENT_DIM))\n",
    "\n",
    "# 2. Top dimensions scatter plots\n",
    "ax2 = axes[1]\n",
    "top_dims = np.argsort(np.abs(correlations))[-2:]  # Top 2 correlated dims\n",
    "scatter = ax2.scatter(final_latents[:, top_dims[0]], final_latents[:, top_dims[1]],\n",
    "                      c=final_carry, cmap='viridis', s=30, alpha=0.7)\n",
    "ax2.set_xlabel(f'Dim {top_dims[0]} (corr={correlations[top_dims[0]]:.2f})', fontsize=12)\n",
    "ax2.set_ylabel(f'Dim {top_dims[1]} (corr={correlations[top_dims[1]]:.2f})', fontsize=12)\n",
    "ax2.set_title('Top Correlated Dimensions', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, ax=ax2, label='Carry Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/latent_dimensions.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Latent dimension analysis saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Compare Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get activations for PCA baseline comparison\n",
    "mono_model.eval()\n",
    "comp_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    all_inputs = torch.tensor(X, dtype=torch.float32).to(DEVICE)\n",
    "    _, mono_h = mono_model(all_inputs)\n",
    "    _, comp_h = comp_model(all_inputs)\n",
    "    mono_act = mono_h.cpu().numpy()\n",
    "    comp_act = comp_h.cpu().numpy()\n",
    "\n",
    "# PCA baseline\n",
    "combined = np.concatenate([mono_act, comp_act], axis=1)\n",
    "pca = PCA(n_components=LATENT_DIM, random_state=RANDOM_SEED)\n",
    "pca_latents = pca.fit_transform(combined)\n",
    "pca_r2, pca_sil = compute_metrics(pca_latents, carry_counts)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"ðŸ“Š METHOD COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Method':<25} {'RÂ²':>10} {'Silhouette':>12} {'Î” vs PCA':>10}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Online Observer':<25} {final_r2:>10.4f} {final_sil:>12.4f} {(final_r2-pca_r2)*100:>+9.1f}%\")\n",
    "print(f\"{'PCA Baseline':<25} {pca_r2:>10.4f} {pca_sil:>12.4f} {'---':>10}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive comparison visualization\n",
    "fig = plt.figure(figsize=(16, 5))\n",
    "gs = GridSpec(1, 3, width_ratios=[1, 1, 1.2])\n",
    "\n",
    "# 1. Bar chart comparison\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "methods = ['Online\\nObserver', 'PCA\\nBaseline']\n",
    "r2_vals = [final_r2, pca_r2]\n",
    "colors = ['#3498db', '#95a5a6']\n",
    "\n",
    "bars = ax1.bar(methods, r2_vals, color=colors, edgecolor='black', linewidth=1.5)\n",
    "for bar, val in zip(bars, r2_vals):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('RÂ² (Linear Accessibility)', fontsize=12)\n",
    "ax1.set_title('RÂ² Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylim(0.85, 1.01)\n",
    "delta_pct = (final_r2 - pca_r2) * 100\n",
    "ax1.annotate(f'+{delta_pct:.1f}%', xy=(0.5, 0.96), fontsize=14, fontweight='bold', \n",
    "             color='green', ha='center')\n",
    "\n",
    "# 2. Silhouette comparison\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "sil_vals = [final_sil, pca_sil]\n",
    "bars = ax2.bar(methods, sil_vals, color=colors, edgecolor='black', linewidth=1.5)\n",
    "for bar, val in zip(bars, sil_vals):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, max(0.01, bar.get_height() + 0.01),\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Silhouette Score', fontsize=12)\n",
    "ax2.set_title('Clustering Comparison', fontsize=14, fontweight='bold')\n",
    "ax2.axhline(y=0, color='gray', linestyle='--')\n",
    "ax2.set_ylim(-0.1, 0.15)\n",
    "\n",
    "# 3. Scatter plot comparison\n",
    "ax3 = fig.add_subplot(gs[2])\n",
    "ax3.scatter(pca_sil, pca_r2, s=200, c='#95a5a6', edgecolors='black', linewidth=2, \n",
    "            label='PCA Baseline', zorder=5)\n",
    "ax3.scatter(final_sil, final_r2, s=200, c='#3498db', edgecolors='black', linewidth=2,\n",
    "            label='Online Observer', zorder=5)\n",
    "ax3.set_xlabel('Silhouette (Clustering)', fontsize=12)\n",
    "ax3.set_ylabel('RÂ² (Accessibility)', fontsize=12)\n",
    "ax3.set_title('Accessibility vs Clustering', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=0.95, color='green', linestyle='--', alpha=0.5)\n",
    "ax3.axvline(x=0.1, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.legend(loc='lower right')\n",
    "ax3.set_xlim(-0.15, 0.2)\n",
    "ax3.set_ylim(0.85, 1.01)\n",
    "\n",
    "# Highlight \"good\" region\n",
    "ax3.fill_between([-0.15, 0.1], 0.95, 1.01, alpha=0.1, color='green')\n",
    "ax3.text(-0.02, 0.98, 'High Access\\nLow Cluster', fontsize=9, color='green', ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/figure_method_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Method comparison visualization saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trajectory data\n",
    "np.savez('../data/online_observer_trajectory.npz',\n",
    "         snapshots=np.array(trajectory['latents']),\n",
    "         epochs=np.array(trajectory['epochs']))\n",
    "\n",
    "# Save final latents\n",
    "np.savez('../data/online_observer_latents.npz',\n",
    "         latents=final_latents,\n",
    "         carry_counts=final_carry,\n",
    "         mono_activations=mono_act,\n",
    "         comp_activations=comp_act,\n",
    "         bit_positions=np.zeros_like(final_carry))  # placeholder\n",
    "\n",
    "print(\"âœ… Data saved to ../data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "gs = GridSpec(2, 3, height_ratios=[1, 1])\n",
    "\n",
    "# 1. Key finding: Transient Clustering\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "ax1.plot(epochs, r2_values, 'g-', linewidth=3, marker='o', markersize=5, label='RÂ² (Accessibility)')\n",
    "ax1.plot(epochs, sil_values, 'r-', linewidth=3, marker='s', markersize=5, label='Silhouette (Clustering)')\n",
    "ax1.axhline(y=0, color='gray', linestyle='-', alpha=0.3)\n",
    "ax1.fill_between(epochs, 0, sil_values, where=np.array(sil_values)>0, alpha=0.2, color='red')\n",
    "ax1.set_xlabel('Training Epoch', fontsize=12)\n",
    "ax1.set_ylabel('Metric Value', fontsize=12)\n",
    "ax1.set_title('KEY FINDING: Clustering is Transient (Scaffolding, Not Structure)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "ax1.legend(loc='center right', fontsize=11)\n",
    "ax1.set_ylim(-0.1, 1.05)\n",
    "\n",
    "# Add phase annotations\n",
    "ax1.annotate('', xy=(peak_epoch, peak_sil), xytext=(peak_epoch, peak_sil+0.15),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "ax1.text(peak_epoch, peak_sil+0.18, f'PEAK\\n{peak_sil:.2f}', ha='center', fontsize=10, \n",
    "         color='red', fontweight='bold')\n",
    "\n",
    "# 2-4. Three phase snapshots\n",
    "for i, (idx, title) in enumerate([(0, 'Phase 1: Init'), (peak_idx, 'Phase 2: Scaffolding'), (-1, 'Phase 3: Final')]):\n",
    "    ax = fig.add_subplot(gs[1, i])\n",
    "    latents = trajectory['latents'][idx]\n",
    "    carries = trajectory['carry_counts'][idx]\n",
    "    pca_temp = PCA(n_components=2, random_state=RANDOM_SEED)\n",
    "    latents_2d = pca_temp.fit_transform(latents)\n",
    "    r2_temp, sil_temp = compute_metrics(latents, carries)\n",
    "    \n",
    "    scatter = ax.scatter(latents_2d[:, 0], latents_2d[:, 1], c=carries, cmap='viridis',\n",
    "                        s=25, alpha=0.7, edgecolors='white', linewidth=0.3)\n",
    "    ax.set_title(f'{title}\\nEpoch {epochs[idx]}', fontsize=12, fontweight='bold')\n",
    "    ax.text(0.02, 0.98, f'RÂ²={r2_temp:.2f}\\nSil={sil_temp:.2f}', transform=ax.transAxes,\n",
    "           fontsize=10, verticalalignment='top', \n",
    "           bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../figures/summary_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"âœ… Summary visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ‰ REPRODUCTION COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ“Š MODELS TRAINED (Online, Concurrently)\")\n",
    "print(f\"   Monolithic MLP: {trajectory['mono_acc'][-1]:.1f}% accuracy\")\n",
    "print(f\"   Compositional Network: {trajectory['comp_acc'][-1]:.1f}% accuracy\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ KEY DISCOVERY: TRANSIENT CLUSTERING\")\n",
    "print(f\"   Peak clustering: Silhouette = {peak_sil:.4f} at epoch {peak_epoch}\")\n",
    "print(f\"   Final state:     Silhouette = {final_sil:.4f}\")\n",
    "print(f\"   Final RÂ²:        {final_r2:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ METHOD COMPARISON\")\n",
    "print(f\"   Online Observer: RÂ² = {final_r2:.4f}\")\n",
    "print(f\"   PCA Baseline:    RÂ² = {pca_r2:.4f}\")\n",
    "print(f\"   Improvement:     +{(final_r2-pca_r2)*100:.1f}%\")\n",
    "\n",
    "print(\"\\nðŸ“ FILES GENERATED\")\n",
    "print(\"   Data:\")\n",
    "print(\"     â€¢ data/online_observer_trajectory.npz\")\n",
    "print(\"     â€¢ data/online_observer_latents.npz\")\n",
    "print(\"   Figures:\")\n",
    "print(\"     â€¢ figures/dataset_visualization.png\")\n",
    "print(\"     â€¢ figures/architecture_comparison.png\")\n",
    "print(\"     â€¢ figures/training_progress.png\")\n",
    "print(\"     â€¢ figures/latent_evolution.png\")\n",
    "print(\"     â€¢ figures/figure5_training_curves.png\")\n",
    "print(\"     â€¢ figures/figure2_delta_latent_space.png\")\n",
    "print(\"     â€¢ figures/latent_dimensions.png\")\n",
    "print(\"     â€¢ figures/figure_method_comparison.png\")\n",
    "print(\"     â€¢ figures/summary_visualization.png\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ’¡ KEY INSIGHT\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\n   CLUSTERING IS SCAFFOLDING, NOT STRUCTURE.\")\n",
    "print(\"\\n   Networks build geometric organization to LEARN,\")\n",
    "print(\"   then DISCARD it once concepts are encoded in weights.\")\n",
    "print(\"\\n   The semantic primitive is in the TRAJECTORY,\")\n",
    "print(\"   not the final representation.\")\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nâœ… All results successfully reproduced!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
